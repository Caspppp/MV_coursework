{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the four models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 02:18:00.012351: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-14 02:18:00.064703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 02:18:00.888567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3323 images belonging to 2 classes.\n",
      "Found 710 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 02:18:01.904758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:01.919196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:01.919446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:01.920920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:01.921165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:01.921356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:02.788543: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:02.788788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:02.788925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-14 02:18:02.789026: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-12-14 02:18:02.789063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14606 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:10:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 02:18:18.961354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-12-14 02:18:20.275501: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cb875c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-14 02:18:20.275602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2023-12-14 02:18:20.288122: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-14 02:18:20.474019: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 68s 357ms/step - loss: 2.1707 - accuracy: 0.5248 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 1.0351 - accuracy: 0.5293 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 0.9029 - accuracy: 0.5287 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 33s 319ms/step - loss: 0.8344 - accuracy: 0.5317 - val_loss: 0.6930 - val_accuracy: 0.5070\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 35s 329ms/step - loss: 0.7641 - accuracy: 0.5317 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 35s 338ms/step - loss: 0.8448 - accuracy: 0.5263 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 34s 326ms/step - loss: 0.7506 - accuracy: 0.5339 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 35s 339ms/step - loss: 0.7902 - accuracy: 0.5299 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 36s 342ms/step - loss: 0.7425 - accuracy: 0.5275 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 35s 335ms/step - loss: 0.8894 - accuracy: 0.5224 - val_loss: 0.6937 - val_accuracy: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with VGG16\n",
      "Epoch 1/10\n",
      "104/104 [==============================] - 44s 360ms/step - loss: 0.8732 - accuracy: 0.5068 - val_loss: 0.7003 - val_accuracy: 0.5070\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 36s 345ms/step - loss: 0.7011 - accuracy: 0.5086 - val_loss: 0.6958 - val_accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 35s 338ms/step - loss: 0.6945 - accuracy: 0.5119 - val_loss: 0.6939 - val_accuracy: 0.4930\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 35s 335ms/step - loss: 0.6946 - accuracy: 0.5083 - val_loss: 0.6930 - val_accuracy: 0.5070\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 34s 325ms/step - loss: 0.6933 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.4930\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 33s 314ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 34s 326ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 33s 315ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 33s 319ms/step - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Training with InceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 63s 358ms/step - loss: 0.9682 - accuracy: 0.5796 - val_loss: 31855.5410 - val_accuracy: 0.5070\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 0.5987 - accuracy: 0.7307 - val_loss: 0.7415 - val_accuracy: 0.6042\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 34s 327ms/step - loss: 0.6372 - accuracy: 0.7571 - val_loss: 1.6190 - val_accuracy: 0.5577\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 35s 332ms/step - loss: 0.5190 - accuracy: 0.7993 - val_loss: 1.5180 - val_accuracy: 0.5465\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 34s 324ms/step - loss: 0.4273 - accuracy: 0.8516 - val_loss: 169.9324 - val_accuracy: 0.5099\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 35s 335ms/step - loss: 0.3003 - accuracy: 0.8971 - val_loss: 406.0359 - val_accuracy: 0.4859\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 0.3614 - accuracy: 0.8562 - val_loss: 136.9081 - val_accuracy: 0.4930\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 34s 329ms/step - loss: 0.3083 - accuracy: 0.8926 - val_loss: 6.9004 - val_accuracy: 0.5648\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 35s 332ms/step - loss: 0.1974 - accuracy: 0.9239 - val_loss: 0.9855 - val_accuracy: 0.6394\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 33s 313ms/step - loss: 0.2964 - accuracy: 0.8884 - val_loss: 227.3578 - val_accuracy: 0.5296\n",
      "Training with MobileNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 58s 331ms/step - loss: 1.0563 - accuracy: 0.6864 - val_loss: 19.3890 - val_accuracy: 0.4930\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 34s 322ms/step - loss: 0.6499 - accuracy: 0.7346 - val_loss: 31.1952 - val_accuracy: 0.4930\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 35s 339ms/step - loss: 0.6615 - accuracy: 0.7316 - val_loss: 6.7901 - val_accuracy: 0.5380\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 35s 334ms/step - loss: 0.6835 - accuracy: 0.7617 - val_loss: 12.7473 - val_accuracy: 0.4930\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 34s 328ms/step - loss: 0.5694 - accuracy: 0.7975 - val_loss: 7.2061 - val_accuracy: 0.4930\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 35s 331ms/step - loss: 0.6079 - accuracy: 0.7833 - val_loss: 3.0739 - val_accuracy: 0.5394\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 32s 311ms/step - loss: 0.5650 - accuracy: 0.7662 - val_loss: 5.5964 - val_accuracy: 0.5070\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 33s 318ms/step - loss: 0.4484 - accuracy: 0.8074 - val_loss: 10.8224 - val_accuracy: 0.3803\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 33s 318ms/step - loss: 0.3104 - accuracy: 0.8697 - val_loss: 11.3108 - val_accuracy: 0.4958\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 33s 318ms/step - loss: 0.2834 - accuracy: 0.8838 - val_loss: 8.3769 - val_accuracy: 0.4338\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "train_dir = './train'\n",
    "validation_dir = './validation'\n",
    "test_dir = './test'\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "def build_model(base_model):\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = {\n",
    "    'ResNet50': ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'VGG16': VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'InceptionV3': InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    'MobileNetV2': MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "}\n",
    "\n",
    "train_histories = {}\n",
    "\n",
    "for name, base_model in models.items():\n",
    "    print(f\"Training with {name}\")\n",
    "    model = build_model(base_model)\n",
    "    history = model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "    train_histories[name] = history\n",
    "    model.save(f'{name}_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_values = {}\n",
    "acc_values = {}\n",
    "\n",
    "for model_name in train_histories:\n",
    "    history = train_histories[model_name].history\n",
    "    loss_values[model_name] = history['loss']\n",
    "    acc_values[model_name] = history['accuracy']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "for model_name in loss_values:\n",
    "    plt.plot(loss_values[model_name], label=model_name)\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for model_name in acc_values:\n",
    "    plt.plot(acc_values[model_name], label=model_name)\n",
    "plt.title('Training Accuracy per Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 images belonging to 2 classes.\n",
      "4/4 [==============================] - 4s 603ms/step - loss: 0.6648 - accuracy: 0.7374\n",
      "模型 ResNet50 在测试集上的准确度: 0.74\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.6888 - accuracy: 0.7374\n",
      "模型 VGG16 在测试集上的准确度: 0.74\n",
      "4/4 [==============================] - 4s 667ms/step - loss: 185.0092 - accuracy: 0.5556\n",
      "模型 InceptionV3 在测试集上的准确度: 0.56\n",
      "4/4 [==============================] - 3s 591ms/step - loss: 4.3439 - accuracy: 0.5960\n",
      "模型 MobileNetV2 在测试集上的准确度: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20934 (\\N{CJK UNIFIED IDEOGRAPH-51C6}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 30830 (\\N{CJK UNIFIED IDEOGRAPH-786E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 19981 (\\N{CJK UNIFIED IDEOGRAPH-4E0D}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 21516 (\\N{CJK UNIFIED IDEOGRAPH-540C}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27169 (\\N{CJK UNIFIED IDEOGRAPH-6A21}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 22411 (\\N{CJK UNIFIED IDEOGRAPH-578B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 22312 (\\N{CJK UNIFIED IDEOGRAPH-5728}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27979 (\\N{CJK UNIFIED IDEOGRAPH-6D4B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 35797 (\\N{CJK UNIFIED IDEOGRAPH-8BD5}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 38598 (\\N{CJK UNIFIED IDEOGRAPH-96C6}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 19978 (\\N{CJK UNIFIED IDEOGRAPH-4E0A}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/environment/miniconda3/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, InceptionV3, MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_dir = './train'\n",
    "validation_dir = './validation'\n",
    "test_dir = './test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_names = ['ResNet50', 'VGG16', 'InceptionV3', 'MobileNetV2']\n",
    "\n",
    "accuracies = []\n",
    "for model_name in model_names:\n",
    "    model = load_model(f'{model_name}_model.h5')\n",
    "    loss, accuracy = model.evaluate(test_generator)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Model {model_name} Accuracy on Test Set: {accuracy:.2f}')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, accuracies, color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Different Models on the Test Set')\n",
    "plt.ylim([0, 1])\n",
    "for i in range(len(accuracies)):\n",
    "    plt.text(i, accuracies[i], f'{accuracies[i]:.2f}', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "histories_dir = './model_histories'\n",
    "if not os.path.exists(histories_dir):\n",
    "    os.makedirs(histories_dir)\n",
    "\n",
    "for name, history in train_histories.items():\n",
    "    history_path = os.path.join(histories_dir, f'{name}_history.csv')\n",
    "    with open(history_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['epoch', 'loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "        \n",
    "        for i in range(len(history.history['loss'])):\n",
    "            writer.writerow([i, \n",
    "                             history.history['loss'][i], \n",
    "                             history.history['accuracy'][i], \n",
    "                             history.history['val_loss'][i], \n",
    "                             history.history['val_accuracy'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 631ms/step\n",
      "Results for InceptionV3_model.h5:\n",
      "Precision: 0.36363636363636365\n",
      "Accuracy: 0.5555555555555556\n",
      "Recall: 0.9230769230769231\n",
      "F1: 0.5217391304347827\n",
      "Specificity: 0.4246575342465753\n",
      "ROC-AUC: 0.6122233930453109\n",
      "Confusion Matrix:\n",
      "TN: 31, FP: 42, FN: 2, TP: 24\n",
      "\n",
      "\n",
      "4/4 [==============================] - 3s 540ms/step\n",
      "Results for MobileNetV2_model.h5:\n",
      "Precision: 0.37037037037037035\n",
      "Accuracy: 0.5959595959595959\n",
      "Recall: 0.7692307692307693\n",
      "F1: 0.5\n",
      "Specificity: 0.5342465753424658\n",
      "ROC-AUC: 0.696259220231823\n",
      "Confusion Matrix:\n",
      "TN: 39, FP: 34, FN: 6, TP: 20\n",
      "\n",
      "\n",
      "4/4 [==============================] - 3s 573ms/step\n",
      "Results for ResNet50_model.h5:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.7373737373737373\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "Specificity: 1.0\n",
      "ROC-AUC: 0.5152792413066385\n",
      "Confusion Matrix:\n",
      "TN: 73, FP: 0, FN: 26, TP: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 522ms/step\n",
      "Results for VGG16_model.h5:\n",
      "Precision: 0.0\n",
      "Accuracy: 0.7373737373737373\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "Specificity: 1.0\n",
      "ROC-AUC: 0.5\n",
      "Confusion Matrix:\n",
      "TN: 73, FP: 0, FN: 26, TP: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/environment/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "models_path = '/home/featurize/data/pretrain/'\n",
    "data_path = '/home/featurize/data/pretrain/test'\n",
    "\n",
    "models = ['InceptionV3_model.h5', 'MobileNetV2_model.h5', 'ResNet50_model.h5', 'VGG16_model.h5']\n",
    "\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     data_path,\n",
    "#     target_size=(image_size, image_size), \n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='binary',  # 或者 'categorical'，\n",
    "#     shuffle=False)\n",
    "\n",
    "\n",
    "def evaluate_model(model_path, test_generator):\n",
    "    model = load_model(model_path, compile=False)\n",
    "    \n",
    "\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in predictions]  \n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    roc_auc = roc_auc_score(y_true, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "\n",
    "    print(f\"Results for {os.path.basename(model_path)}:\")\n",
    "    print(f\"Precision: {report['1']['precision']}\")\n",
    "    print(f\"Accuracy: {report['accuracy']}\")\n",
    "    print(f\"Recall: {report['1']['recall']}\")\n",
    "    print(f\"F1: {report['1']['f1-score']}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "for model_name in models:\n",
    "    model_path = os.path.join(models_path, model_name)\n",
    "    evaluate_model(model_path, test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
